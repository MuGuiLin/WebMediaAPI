<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script async src="//hm.baidu.com/hm.js?f79493fc378b2235419a88daa91d5f6d"></script>
  <title>Web Audio API examples: MediaElementAudioSource()</title>
  <style>
    body {
      padding: 50px;
    }

    h1 {
      text-align: center;
    }

    h3 {
      line-height: 32px;
      font-weight: normal;
    }

    section {
      margin: 100px auto;
      width: 1200px;
    }

    audio,
    input[type="file"] {
      width: 471px;
    }

    label {
      position: relative;
    }

    .VL,
    .VR,
    #VLV,
    #VRV,
    #TBLV,
    #TBRV {
      position: absolute;
      top: 30px;
      left: 0;
    }

    .VR {
      left: auto;
      right: -22px;
    }


    #VLV {
      top: 50px;
      left: 20px;
    }

    #VRV {
      top: 50px;
      left: 150px;
    }

    #TBLV {
      left: auto;
      top: 80px;
      right: 10px;
    }

    #TBRV {
      left: 20px;
      top: 80px;
      right: auto;
    }

    meter {
      width: 128px;
      transform: rotate(-90deg);
    }

    button {
      font-size: 16px;
    }

    h4 {
      padding: 30px 60px;
      color: red;
      line-height: 32px;
      font-weight: normal;
    }

    h2 {
      padding: 0 60px;
      color: blue;
    }
  </style>
</head>

<body>
  <h1>Web Audio API examples: AudioWorkletNode() 获取Video/Audio视音频声道(左右声道|多声道)</h1>
  <hr />

  <h4>
    之前通过createScriptProcessor()来获取视音频声道，由于W3C不再推荐使用该特性。所以在不久的将来也许会从相关的Web标准中移除，也许正准备移除或出于兼容性而保留。<br>

    但尽管如此：目前所有现代浏览器包括早期点的浏览器均得到了很好的支持，还没有在哪个浏览器上被正式的移除。<br>

    所以来尝试使用 AudioWorkletNode() 来替代上面的createScriptProcessor()
    ，AudioWorkletNode()在目前看来几乎所有的主流浏览器都支持它，但需要注意的是：它现在还是一项实验性技术。<br>

    以上两个API从性能上相比较：AudioWorkletNode() 比 ScriptProcessorNode() 性能要更好些，并且更易于使用，并且它还支持更多个的输入和输出通道。
  </h4>

  <h2>注：请在http服务器环境中运行该实例！！</h2>

  <section>
    <label>
      <button type="button" id="LBTN">左声道（L）</button>
      <input type="range" id="VL" min="0" max="10" step="0.1" class="VL" value="1" />
      <span id="VLV">音量：1.0</span>
      <meter id="L" min="-60" low="-20" high="-6" max="3" value="-60" style="margin-left: 13px"></meter>
      <span id="TBLV">峰值电平：-60</span>
    </label>
    添加本地视音频：<input id="file" type="file" accept="video/*,audio/*" />

    <label>
      <meter id="R" min="-60" low="-20" high="-6" max="3" value="-60"></meter>
      <span id="TBRV">峰值电平：-60</span>
      <button type="button" id="RBTN">右声道（R）</button>
      <input type="range" id="VR" min="0" max="10" step="0.1" class="VR" value="1" />
      <span id="VRV">音量：1.0</span>
    </label>

    <br /><br />

    <div class="box">
      <button type="button" id="SLBTN">左环绕（SL）</button>
      <meter id="SL" min="-60" low="-20" high="-6" max="3" value="-60"></meter>

      <!--<audio  controls loop width="600">
          <source src="./media/xxx.mp3" type="audio/mp3" />
        </audio>-->
      <video controls width="600">
        <source src="./media/Project DT-5.1.mp4" type="video/mp4" />
      </video>

      <meter id="SR" min="-60" low="-20" high="-6" max="3" value="-60"></meter>
      <button type="button" id="SRBTN">右环绕（SR）</button>
    </div>
    <section>

      <script>
        // 获取本地视音频
        file.addEventListener("change", function () {
          const file = this.files[0];
          console.log(file);
          if ("video/mp4".startsWith("video")) {
            // video.src = window.URL.createObjectURL(file);
            audio.src = window.URL.createObjectURL(file);
          } else {
            audio.src = window.URL.createObjectURL(file);
          }
        });

        function getBaseLog(x, y) {
          return Math.log(y) / Math.log(x);
        };

        // 计算音频Peak Level
        function countPeakLevel(float) {
          return getBaseLog(10, float) * 20;
        };

        // const audio = document.querySelector("audio");
        const audio = document.querySelector("video");
        let ac = null;

        // 音频元数据加载后执行
        audio.addEventListener("loadedmetadata", async () => {
          if (!ac) {
            // 上下文对象 由于浏览器安全策略要求音频上下文必须在用户事件（单击、键盘按键等）中启用。这意味着，如果您尝试在没有用户事件的情况下自动播放音乐，所以在loadedmetadata元数据已加载时再执行！！
            ac = new (window.AudioContext || window.webkitAudioContext)();

            // 创建并获取输入源
            const audioSource = ac.createMediaElementSource(audio);
            // 缓冲区大小 取值为 2 的幂次方的一个常数
            const bufferSize = 2048;
            // 音频通道数 默认值是 2，最高能取 32
            const channelCount = 4 || audioSource.channelCount;

            // 创建音频处理器
            await ac.audioWorklet.addModule('./processor.js');
            const processor = new AudioWorkletNode(ac, 'mu-processor', {
              // numberOfInputs: 1, // 初始化 numberOfInputs 属性的值。默认为 1。
              // numberOfOutputs: 1, // 初始化 numberOfOutputs 属性的值。默认为 1。
              // outputChannelCount: [], // 定义每个输出的通道数，例如：outputChannelCount: [n, m] 指定第一个输出中的通道数为 n，第二个输出中的通道数为 m。数组长度必须匹配 numberOfOutputs。
              // parameterData: {}, // 节点上的自定义 AudioParam 对象的初始值（在其 parameters 属性中），其中 key 为自定义参数的名称，value 为其初始值。
              // processorOptions: {} // 可用于基础 AudioWorkletProcessor 的自定义初始化的任何其他数据。
            });

            // 链接音频处理器
            audioSource.connect(processor).connect(ac.destination);

            // 创建通道控制器
            const volumeNodeL = new GainNode(ac, { gain: 1 });
            const volumeNodeR = new GainNode(ac, { gain: 1 });
            const volumeNodeSL = new GainNode(ac, { gain: 1 });
            const volumeNodeSR = new GainNode(ac, { gain: 1 });

            // 创建通道分配器
            const splitterNode = new ChannelSplitterNode(ac, {
              numberOfOutputs: channelCount,
            });

            splitterNode.connect(volumeNodeL, 0);
            splitterNode.connect(volumeNodeR, 1);
            splitterNode.connect(volumeNodeSL, 2);
            splitterNode.connect(volumeNodeSR, 3);

            // 控制链接到输入源
            audioSource.connect(splitterNode);

            // 创建通道合并器
            const mergerNode = new ChannelMergerNode(ac, {
              numberOfInputs: channelCount,
            });

            volumeNodeL.connect(mergerNode, 0, 0);
            volumeNodeR.connect(mergerNode, 0, 1);
            volumeNodeSL.connect(mergerNode, 0, 2);
            volumeNodeSR.connect(mergerNode, 0, 3);

            // 通道链接到扬声器
            mergerNode.connect(ac.destination);

            audio.play();

            // 监听音频处理器每次处理的样本帧
            processor.port.onmessage = (evt) => {
              if ('peaks' === evt.data.type) {
                const [l, r, sl, sr] = evt.data;

                // 声轨1
                if (volumeNodeL.gain.value && l) {
                  L.value = countPeakLevel(l);
                  TBLV.innerText = '峰值电平：' + L.value.toFixed(2);
                }
                // 声轨2
                if (volumeNodeR.gain.value && r) {
                  R.value = countPeakLevel(r);
                  TBRV.innerText = '峰值电平：' + R.value.toFixed(2);
                }
                // 声轨3
                if (volumeNodeSL.gain.value && sl) {
                  SL.value = countPeakLevel(sl);
                }
                // 声轨4
                if (volumeNodeSR.gain.value && sr) {
                  SR.value = countPeakLevel(sr);
                }

              }
            };

            processor.port.onmessageerror = (err) => {
              console.error(err);
            }
            // 静音左L声道
            LBTN.onclick = function () {
              volumeNodeL.gain.value = Number(!volumeNodeL.gain.value);
            };

            // 左L声道音量大小控制
            VL.oninput = function () {
              // volumeNodeL.gain.value = this.value;
              volumeNodeL.gain.setValueAtTime(this.value, ac.currentTime);
              VLV.innerText = '音量：' + this.value;
            };

            // 静音右R声道
            RBTN.onclick = function () {
              volumeNodeR.gain.value = Number(!volumeNodeR.gain.value);
            };

            // 右R声道音量大小控制
            VR.oninput = function () {
              volumeNodeR.gain.setValueAtTime(this.value, ac.currentTime);
              VRV.innerText = '音量：' + this.value;
            };

            // 静音左环绕SL声道
            SLBTN.onclick = function () {
              volumeNodeSL.gain.value = Number(!volumeNodeSL.gain.value);
            };

            // 静音右环绕SR声道
            SRBTN.onclick = function () {
              volumeNodeSR.gain.value = Number(!volumeNodeSR.gain.value);
            };
          } else {
            audio.play();
          };
        }, false);

        // 监听音频播放时，激活当前播放
        audio.addEventListener('play', () => {
          ac.resume();
        }, false);

        // 监听音频暂停时，挂起当前播放
        audio.addEventListener('pause', () => {
          ac.suspend();
        }, false);

      </script>
</body>

</html>