<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>audio音频裁剪</title>
    <style>
      body {
        padding: 100px;
        font-size: 16px;
        line-height: 32px;
      }
      input[type="range"] {
        width: 500px;
      }
      button {
        font-size: 16px;
      }
      progress {
        width: 1000px;
      }
    </style>
  </head>
  <body>
    <h1>AudioBuffer对象 实现audio音频裁剪</h1>
    <hr />

    <h4>音频来源信息：</h4>
    从本地获取视音频文件：<input type="file" id="file" />
    <br />
    <button type="button" id="fetchBtn">从网络获取视音频文件</button>
    <ul>
      <li>
        音频时长：<b id="duration">00.00</b>， 数据长度：<b id="lengths">0</b>，
        声道数量：<b id="numberOfChannels">0</b>， 采样率：<b id="sampleRate"
          >0</b
        >
      </li>
    </ul>
    <hr />

    <h4>历史音频列表：</h4>
    <ul id="list"></ul>
    <hr />

    <h4>音频裁剪操作：</h4>
    <label>
      裁剪起始时间：<input
        type="range"
        id="start"
        step="0.01"
        min="0"
        value="0"
      />
      <b id="startOffsetVal">0.00</b>
    </label>
    <br />
    <label>
      裁剪结束时间：<input
        type="range"
        id="end"
        step="0.01"
        min="0"
        value="0"
      />
      <b id="endOffsetVal">0.00</b>
    </label>
    <br />
    <hr />
    <br />
    <button id="cropping">裁剪</button>
    <button id="play">初始化裁剪音频</button>
    <button id="mute">静音 / 取消静音</button>
    <button id="resumeOrsuspend">播放 / 暂停</button>

    <h4>音频播放响度：</h4>
    <progress id="progress" max="1000" value="0"></progress>

    <script>
      let renderInter;
      {
        // 如果音频是关闭状态，则重新新建一个全局音频上下文
        // if (ac.state === 'closed') {
        //   ac = new (window.AudioContext || window.webkitAudioContext)();
        // }
        const ac = new (window.AudioContext || window.webkitAudioContext)();
        ac.onstatechange = function (e) {
          console.log("当AudioContext的状态发生变化时执行：", ac.state, e);
          if ("suspended" === ac.state) {
            getByteFrequencyData();
          }
          if ("running " === ac.state) {
            renderInter && clearInterval(renderInter);
          }
        };

        let audioBuffer = [];
        let audioBuffers = [];
        let newAudioBuffer = [];
        let startOffset = 0;
        let endOffset = 0;

        function setStartVal(value, is) {
          if (is) {
            start.max = value;
            start.value = 0;
          } else {
            startOffset = value;
            startOffsetVal.innerText = value;
          }
        }
        start.oninput = function () {
          setStartVal(this.value);
        };

        function setEndVal(value, is) {
          if (is) {
            end.max = value;
            end.value = value;
          }
          endOffset = value;
          endOffsetVal.innerText = value;
        }
        end.oninput = function () {
          setEndVal(this.value);
        };

        // 裁剪
        cropping.onclick = function () {
          /**
            先创建一个空的AudioBuffer，
            再根据裁剪起始和结束时间复制现有的通道所对应的数据，然后复制的内容写入到这个空的AudioBuffer，
            就可以得到一个剪裁后的音频Buffer数据。
          */

          var channels = audioBuffer.numberOfChannels;
          var rate = audioBuffer.sampleRate;

          // 截取前10秒
          var startOffset2 = 0;
          // var endOffset2 = rate * 10;
          var endOffset2 = rate * endOffset;
          // 3秒对应的帧数
          var frameCount = endOffset2 - startOffset2;

          // 创建同样采用率、同样声道数量，长度是前endOffset秒的空的AudioBuffer
          newAudioBuffer = new AudioContext().createBuffer(
            channels,
            endOffset2 - startOffset2,
            rate
          );
          // 创建临时的Array存放复制的buffer数据
          var anotherArray = new Float32Array(frameCount);
          // 声道的数据的复制和写入
          var offset = 0;
          for (var channel = 0; channel < channels; channel++) {
            audioBuffer.copyFromChannel(anotherArray, channel, startOffset2);
            newAudioBuffer.copyToChannel(anotherArray, channel, offset);
          }
          console.log("newAudioBuffer：", newAudioBuffer);
        };

        let gainNode;
        let analyser;
        function playAudioBuffer(buffer) {
          // 创建AudioBufferSourceNode对象
          const bufferSource = ac.createBufferSource();
          bufferSource.buffer = buffer;
          bufferSource.onended = function (res) {
            console.log("播放结束！");
          };

          // 创建音量控制节点
          gainNode = ac.createGain();
          // gainNode.gain.value = gainValue;

          // 创建音频分析节点
          analyser = ac.createAnalyser();
          // analyser.fftSize = fftSize;

          bufferSource.connect(analyser);
          analyser.connect(gainNode);
          gainNode.connect(ac.destination);

          bufferSource.start(0);
          getByteFrequencyData();
          console.log(ac, bufferSource, gainNode);
        }

        // 获取音频解析数据
        function getByteFrequencyData() {
          const arr = new Uint8Array(analyser.frequencyBinCount);
          analyser.getByteFrequencyData(arr);
          // console.log("音频解析数据：", arr);
          progress.value =
            ~~Object.values(arr).reduce((a, b) => a + b, 0) * 0.01;
          renderInter = window.requestAnimationFrame(getByteFrequencyData);
        }

        play.onclick = function () {
          playAudioBuffer(newAudioBuffer);
        };

        // 静音
        mute.onclick = function () {
          gainNode.gain.value = Number(!gainNode.gain.value);
        };

        // 播放/暂停
        resumeOrsuspend.onclick = function () {
          if ("suspended" === ac.state) {
            // 注：只有在当前AudioContext被挂起的状态下，才能使用resume进行重新激活 来实现播放
            ac.resume();
          } else {
            // 挂起当前播放 来实现暂停
            ac.suspend();
          }
        };

        function adoBufferList(buffer, file) {
          audioBuffers.push(buffer);
          const li = document.createElement("li");
          li.innerHTML = `音频名称：${file?.name}，音频大小：${file?.size}，音频时长：${buffer.duration}`;
          list.append(li);
        }

        function setAudioBuffer(buffer, file) {
          audioBuffer = buffer;
          // playAudioBuffer(buffer);

          setStartVal(buffer.duration, 1);
          setEndVal(buffer.duration, 1);
          adoBufferList(buffer, file);

          duration.innerText = buffer.duration;
          lengths.innerText = buffer.length;
          numberOfChannels.innerText = buffer.numberOfChannels;
          sampleRate.innerText = buffer.sampleRate;
        }

        file.onchange = function (ev) {
          const file = this.files[0] || ev.target.files[0];
          const fr = new FileReader();
          fr.onload = function (res) {
            console.log("FileReader", res.target);
            console.log("ArrayBuffer", res.target.result); // 音频数据的ArrayBuffer对象

            // 使用AudioContext对象的decodeAudioData()方法 将ArrayBuffer对象 转为 AudioBuffer对象
            ac.decodeAudioData(res.target.result, function (buffer) {
              console.log("AdecodeAudioData => udioBuffer", buffer);
              setAudioBuffer(buffer, file);
            });
          };
          fr.readAsArrayBuffer(file); // 通过 readAsArrayBuffer() 方法，读取所上传的音频文件数据（如：MP3格式、OGG格式还是WAV格式，在加载成功后就可获取 ArrayBuffer类型音频数据。
        };

        fetchBtn.onclick = function () {
          const src = "./media/AAC-5.1.mp4";
          fetch(src)
            .then((response) => {
              console.log(response);
              return response.arrayBuffer();
            })
            .then((arrayBuffer) => {
              return ac.decodeAudioData(arrayBuffer);
            })
            .then((audioBuffer) => {
              setAudioBuffer(audioBuffer, { name: src });

              return;
              // 获取音频源并创建两个独立的音频源
              let sourceLeft = ac.createBufferSource();
              let sourceRight = ac.createBufferSource();

              // 分别将音频数据赋值给左右两个音频源
              sourceLeft.buffer = audioBuffer;
              sourceRight.buffer = audioBuffer;

              // 创建两个分轨并分别连接至音频源
              let trackLeft = ac.createGain();
              let trackRight = ac.createGain();

              sourceLeft.connect(trackLeft);
              sourceRight.connect(trackRight);

              trackLeft.connect(ac.destination);
              trackRight.connect(ac.destination);

              // 开始播放
              sourceLeft.start();
              sourceRight.start();

              // 停止播放
              // sourceLeft.stop();
              // sourceRight.start();

              // 静音
              // trackLeft.gain.value = Number(!trackLeft.gain.value);
              // trackRight.gain.value = Number(!trackRight.gain.value);
            });
        };
      }
    </script>
  </body>
</html>
